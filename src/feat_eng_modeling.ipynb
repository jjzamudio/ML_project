{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures,OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_dir = '../data/'\n",
    "data_path = \"data_clean.csv\"\n",
    "data = pd.read_csv(filepath_or_buffer= folder_dir + data_path, header=0)\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "#=data.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3902210, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome    True\n",
       "nasty      True\n",
       "pitcher    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()[data.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['umpcall', 'outcome', 'start_speed', 'pfx_x', 'pfx_z', 'px', 'pz',\n",
       "       'break_y', 'break_angle', 'break_length', 'pitch_type', 'spin_dir',\n",
       "       'nasty', 'pitch_count', 'descr', 'y', 'year', 'strikes', 'balls',\n",
       "       'pitcher', 'pitch_type.1', 'count_b_p', 'zone_1', 'zone_2', 'zone_3',\n",
       "       'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9', 'zone_11',\n",
       "       'zone_12', 'zone_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create features\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_feats=['px','pz','pfx_x','pfx_z','start_speed','spin_dir','pitch_count','count_b_p']\n",
    "model_feats=['px','pz','pfx_x','pfx_z','start_speed','spin_dir','pitch_count','balls','strikes']\n",
    "\n",
    "y=data['y']\n",
    "data=data[model_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "start = data[\"date\"].searchsorted(datetime.datetime(2012, 1, 1))[0]\n",
    "#start\n",
    "end = data[\"date\"].searchsorted(datetime.datetime(2017, 1, 1))[0] - 1\n",
    "#end\n",
    "\n",
    "X_train = data[model_feats].loc[start:end]\n",
    "y_train=X_train['y']\n",
    "X_train=X_train.drop(['y'],axis=1)\n",
    "\n",
    "X_test=data[model_feats][end:]\n",
    "y_test=X_test['y']\n",
    "X_test=X_test.drop(['y'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create pipeline\n",
    "my_cv = TimeSeriesSplit(n_splits=3).split(X_train)\n",
    "steps= [('polyfeat', PolynomialFeatures()),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('lr', LogisticRegression())]\n",
    "\n",
    "mypipeline= Pipeline(steps)\n",
    "parameters = dict(lr__C = [10**i for i in range(-5, 5)],\n",
    "                  lr__penalty = ['l1', 'l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_grid_search= GridSearchCV(mypipeline, \n",
    "                             param_grid = parameters,  \n",
    "                             scoring = 'log_loss',\n",
    "                             n_jobs=2, \n",
    "                             refit=True)\n",
    "\n",
    "lr_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_1 = lr_grid_search.best_score_\n",
    "print(best_1)\n",
    "lr_grid_search.best_estimator_\n",
    "model=lr_grid_search.best_estimator_.steps[2][1]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=lr_grid_search.best_estimator_.steps[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities_lr=model.predict_proba(X_test)[:,1]\n",
    "np.savetxt'probabilities_lr.txt', probabilities_lr, delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_dict = {}\n",
    "for coef, feat in zip(model.coef_[0],X_train.columns.tolist()):\n",
    "    coef_dict[feat] = coef\n",
    "coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps= [('polyfeat', PolynomialFeatures()), ('scaler', StandardScaler()),('rf', RandomForestClassifier())]\n",
    "\n",
    "steps= [('rf', RandomForestClassifier())]\n",
    "\n",
    "mypipeline= Pipeline(steps)\n",
    "\n",
    "param_grid_rf = dict(\n",
    "    #rf__min_samples_leaf= np.logspace(4, 5, num=5, base=4, endpoint=False, dtype=int),\n",
    "    rf__min_samples_split= [100, 1000],\n",
    "    rf__max_depth= list(range(4,9,2)),\n",
    "    rf__n_estimators= list(range(200,500,100))\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_grid_search= GridSearchCV(mypipeline, \n",
    "                             param_grid = param_grid_rf, \n",
    "                             scoring = 'log_loss',\n",
    "                                    n_jobs=-1, refit=True)\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_1 = rf_grid_search.best_score_\n",
    "print(best_1)\n",
    "rf_grid_search.best_estimator_\n",
    "model=rf_grid_search.best_estimator_.steps[2][1]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=rf_grid_search.best_estimator_.steps[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get class probabilities\n",
    "probabilities_rf = model.predict_proba(X_test)\n",
    "print('\\rSaving class probabilities.', end='\\r')\n",
    "np.savetxt(folder_dir + 'probabilities_rf.txt', probabilities_rf, delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOP="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF Feature Importances\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "plt.bar(range(len(indices)), importances[indices], color=\"r\", align=\"center\")\n",
    "plt.title('Feature Importances Bar Plot')\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.xticks(range(len(indices)), train_val.drop('Y', axis=1).columns[indices], rotation=45, horizontalalignment='right')\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.title('Feature Importance Graph for RF')\n",
    "plt.show()\n",
    "print('\\rSaving feature_importances barplot... ', end='')\n",
    "fig.savefig(rf_dir + 'feature_importances_rf.png')\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
